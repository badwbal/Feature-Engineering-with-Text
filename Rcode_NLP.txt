#-----Section 01-------------------------------------------
# get the data

# set working directory
setwd(dirname(file.choose()))
getwd()

# import the CSV file into a data frame
SMSSpam_raw <- read.csv()

#-----Section 02-------------------------------------------
# Exploring and preparing the data

# Examine the structure of the sms data
str(SMSSpam_raw)

# convert spam/ham to factor.
SMSSpam_raw$type <- factor(SMSSpam_raw$type)

# examine the type variables
str(SMSSpam_raw$type)
table(SMSSpam_raw$type)
prop.table(table(SMSSpam_raw$type))           

# randomize the order of the sms data
set.seed(12345)                           
SMSSpam_raw <- SMSSpam_raw[order(runif(5572)), ]  

#-----Section 03-------------------------------------------
# Make variable 'text' into a corpus using the text mining (tm) package

library(tm)
SMSSpam_corpus <- Corpus(VectorSource(SMSSpam_raw$text))

# Examine the sms corpus
print(SMSSpam_corpus)
inspect(SMSSpam_corpus[1:5])

# Clean up the corpus using tm_map()
corpus_clean <- tm_map(SMSSpam_corpus, tolower)
corpus_clean <- tm_map(SMSSpam_corpus, removeNumbers)
corpus_clean <- tm_map(SMSSpam_corpus, removeWords, stopwords())
corpus_clean <- tm_map(SMSSpam_corpus, removePunctuation)
corpus_clean <- tm_map(SMSSpam_corpus, stripWhitespace)

inspect(corpus_clean[1:5])


stop.char <- unlist(read.table("stop_char.txt", stringsAsFactors=FALSE))
corpus_clean <- tm_map(corpus_clean, removeWords, stop.char)

inspect(corpus_clean[1:5])

# apply stemming
# corpus_clean <- tm_map(corpus_clean, stemDocument)

# ensure corpus is still a PlainTextDocument
corpus_clean <- tm_map(corpus_clean, PlainTextDocument)

# Examine the clean corpus
inspect(SMSSpam_corpus[1:3])
inspect(corpus_clean[1:3])

#-----Section 04------------------------------------------
# Create a document-term sparse matrix

SMSSpam_dtm <- DocumentTermMatrix(corpus_clean)
SMSSpam_dtm

# Find most frequent terms
findFreqTerms(SMSSpam_dtm, lowfreq=100)

# Find associations for words with lower correlation limit
findAssocs(SMSSpam_dtm, 'free', 0.25)
findAssocs(SMSSpam_dtm, 'claim', 0.25)

#-----Section 05------------------------------------------
# Creating training(75%) and test (25%)datasets
SMSSpam_raw_train <- SMSSpam_raw[1:4179, ]
SMSSpam_raw_test  <- SMSSpam_raw[4180:5572, ]

SMSSpam_dtm_train <- SMSSpam_dtm[1:4179, ]
SMSSpam_dtm_test  <- SMSSpam_dtm[4180:5572, ]

SMSSpam_corpus_train <- corpus_clean[1:4179]
SMSSpam_corpus_test  <- corpus_clean[4180:5572]

# Check that the proportion of spam is similar
prop.table(table(SMSSpam_raw_train$type))
prop.table(table(SMSSpam_raw_test$type))

#-----Section 06------------------------------------------
# Optional wordcloud visualization -----------------

library(wordcloud)

wordcloud(SMSSpam_corpus_train, min.freq = 60, random.order = FALSE)

# Subset the training data into spam and ham groups
spam <- subset(SMSSpam_raw_train, type == "spam")
ham  <- subset(SMSSpam_raw_train, type == "ham")

wordcloud(spam$text, max.words = 30, scale = c(3, 0.5), random.order=FALSE)
wordcloud(ham$text, max.words = 30, scale = c(3, 0.5), random.order=FALSE)



#-----Section 07------------------------------------------
# Create a dictionary of more frequent appearing words

SMSSpam_dict <- findFreqTerms(SMSSpam_dtm_train, lowfreq=5)
SMSSpam_dict

# limit the train and test data sets to the terms in the dictionary
SMSSpam_train <- DocumentTermMatrix(SMSSpam_corpus_train, list(dictionary = SMSSpam_dict))
SMSSpam_test  <- DocumentTermMatrix(SMSSpam_corpus_test, list(dictionary = SMSSpam_dict))

# convert counts to a factor
convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0)
  x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
}

# apply() convert_counts() to columns (MARGIN=2) of train and test data
SMSSpam_train <- apply(SMSSpam_train, MARGIN = 2, convert_counts)
SMSSpam_test  <- apply(SMSSpam_test, MARGIN = 2, convert_counts)

#-----Section 08------------------------------------------
# training a model on the data

library(e1071)
SMSSpam_classifier <- naiveBayes(SMSSpam_train, SMSSpam_raw_train$type)
SMSSpam_classifier

#-----Section 09------------------------------------------
# evaluating model performance

SMSSpam_test_pred1 <- predict(SMSSpam_classifier, SMSSpam_test)

library(gmodels)
CrossTable(SMSSpam_test_pred1, SMSSpam_raw_test$type,
           prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
           dnn = c('predicted', 'actual'))


# see more diagnostics
CrossTable(SMSSpam_test_pred1, SMSSpam_raw_test$type, dnn = c('predicted', 'actual'))

# and yet more diagnostics (see page 302)
library(caret)
confusionMatrix(SMSSpam_test_pred1, SMSSpam_raw_test$type, positive = "spam")

#-----Section 10------------------------------------------
# improving model performance 
# set Laplace (smoothing) estimator to 1

SMSSpam_classifier2 <- naiveBayes(SMSSpam_train, SMSSpam_raw_train$type, laplace = 1)
SMSSpam_test_pred2 <- predict(SMSSpam_classifier2, SMSSpam_test)
CrossTable(SMSSpam_test_pred2, SMSSpam_raw_test$type,
           prop.chisq = FALSE, prop.t = FALSE, prop.r = FALSE,
           dnn = c('predicted', 'actual'))

# see more diagnostics
CrossTable(SMSSpam_test_pred2, SMSSpam_raw_test$type, dnn = c('predicted', 'actual'))

# and yet more diagnostics (see page 302)
library(caret)
confusionMatrix(SMSSpam_test_pred2, SMSSpam_raw_test$type, positive = "spam")

#-----Section 11------------------------------------------
# save the model for future use

save(SMSSpam_classifier2, file = "SMSSpam_classifier.rda")

#-----Section 12------------------------------------------
# remove all variables from the environment

rm(list=ls())



